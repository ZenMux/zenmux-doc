# Streaming

ZenMux allows any model to return generation results progressively in a streaming manner, rather than returning a complete response all at once. Streaming enables users to see the first token generated by the large language model immediately, reducing user wait times. This approach can significantly enhance user experience, particularly for real-time conversations, long text generation, and similar scenarios.

You can enable streaming mode by setting the `stream` parameter to `true` in your request to receive streaming responses. Here are two implementation examples:

## Method 1: Using OpenAI Compatible Interface (Recommended)

::: code-group

```python [Python]
from openai import OpenAI

client = OpenAI(
    base_url="https://zenmux.ai/api/v1",
    api_key="<your_ZENMUX_API_KEY>", # [!code highlight]
)

stream = client.chat.completions.create(
    model="openai/gpt-5",
    messages=[
        {
            "role": "user",
            "content": "What is the meaning of life?" 
        }
    ],
    # Enable streaming mode by setting stream=True
    stream=True, # [!code highlight]
)

# When streaming mode is enabled (stream=True), the returned content will change.
# You need to access each individual chunk in the return value through a loop
for chunk in stream: # [!code highlight]
	delta = chunk.choices[0].delta # [!code highlight] <-- Use the delta field
 
	if delta.content:
		print(delta.content, end="")
```

```ts [TypeScript]
import OpenAI from "openai";

const openai = new OpenAI({
  baseURL: "https://zenmux.ai/api/v1",
  apiKey: "<your_ZENMUX_API_KEY>", // [!code highlight]
});

async function main() {
  const stream = await openai.chat.completions.create({
    model: "openai/gpt-5",
    messages: [
      {
        role: "user",
        content: "What is the meaning of life?",
      },
    ],
    // Enable streaming mode by setting stream=true
    stream: true, // [!code highlight]
  });

  // When streaming mode is enabled (stream=true), the returned content will change.
  // You need to access each individual chunk in the return value through a loop
  for await (chunk of stream) { // [!code highlight] 
    delta = chunk.choices[0].delta // [!code highlight] <-- Use the delta field
    
    if (delta.content) {
        console.log(delta.content)
    }
  }
}

main();
```

:::

---

## Method 2: Direct ZenMux API Call

::: code-group

```python [Python (httpx)]
import httpx
import json

async def stream_openai_chat_completion():
    api_key = "<your_ZENMUX_API_KEY>" # [!code highlight]
    headers = {
        "Authorization": f"Bearer {api_key}",
    }
    payload = {
        "model": "openai/gpt-5",
        "messages": [
            {
                "role": "user",
                "content": "What is the meaning of life?"
            }
        ],
        "stream": True # [!code highlight]
    }

    async with httpx.AsyncClient() as client:
        async with client.stream(method="POST", url="https://zenmux.ai/api/v1/chat/completions", headers=headers, json=payload, timeout=None) as response:
            response.raise_for_status()

            async for chunk in response.aiter_bytes():
                decoded_chunk = chunk.decode('utf-8')
                print(decoded_chunk)

if __name__ == "__main__":
    import asyncio
    asyncio.run(stream_openai_chat_completion())

```

```typescript [TypeScript (fetch)]
fetch("https://zenmux.ai/api/v1/chat/completions", {
  method: "POST",
  headers: {
    Authorization: "Bearer <your_ZENMUX_API_KEY>", // [!code highlight]
    "Content-Type": "application/json",
  },
  body: JSON.stringify({
    model: "openai/gpt-5", 
    messages: [
      {
        role: "user",
        content: "What is the meaning of life?",
      },
    ],
    stream: true // [!code highlight]
  }),
})
  .then(async (response) => {
    const textDecoder = new TextDecoder();
    for await (const chunk of response.body) {
      const textChunk = textDecoder.decode(chunk);
      console.log(textChunk)
    }
  })

```

```bash [Shell (cURL)]

curl "https://zenmux.ai/api/v1/chat/completions" \
  -H "Content-Type: application/json" \ 
  -H "Authorization: Bearer $ZENMUX_API_KEY" \
  -d '{  
    "model": "openai/gpt-5", 
    "messages": [ 
      { 
        "role": "user", 
        "content": "What is the meaning of life?" 
      } 
    ], 
    "stream": true
  }'
```