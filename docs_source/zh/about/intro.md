# 简介

## ZenMux 概述

ZenMux 是全球首个支持**保险赔付机制**的企业级大模型聚合平台。通过平台可一站式调用各渠道的最新大模型，在使用过程中遇到的效果不佳、延时过高等问题，将通过**智能保险检测与赔付机制**进行自动补偿，全方位解决企业对 AI 幻觉、质量不稳定的担忧。

我们的核心理念是**开发者友好**。除提供统一的 API 接口访问 OpenAI、Anthropic、Google、DeepSeek 等全球主流大语言模型外，更在 API 调用日志分析、Cost（成本）、Usage（用量）、Performance（性能）等功能上持续深度打磨，为开发者提供全面的可观测性支持。

**平台核心优势：**

- **原生双协议支持**：完整兼容 OpenAI 和 Anthropic 两大协议标准，可无缝集成到 Claude Code 等主流开发工具中
- **透明的质量保障**：定期对全渠道所有模型进行"降智检测"（HLE 测试），检测过程和结果在 GitHub 开源（单次检测投入约 $4000）
- **智能路由与保险**：自动选择最优模型，并为输出质量提供保险兜底保障
- **企业级服务**：高容量储备、自动故障转移、全球边缘节点加速

::: tip 💡 充值优惠
平台目前提供 20% 充值折扣，支持Stripe信用卡和支付宝充值。欢迎体验并提供反馈。
:::

### 产品名称释义

**ZenMux** 是 **Zen（禅）** 和 **Mux（Multiplexer，多路复用器）** 的组合词：

::: tip Zen（禅）的含义
体现产品的核心理念：将复杂的多模型选择、风险管理、API 调用等繁琐流程，通过智能化手段简化为"一个 API、一套 SDK、一个平台"的极简体验。同时提供保险兜底机制，减少用户在使用 AI 过程中遇到幻觉等问题的后顾之忧。
:::

::: tip Mux（Multiplexer，多路复用器）的含义
体现产品的核心功能：聚合多家 AI 模型供应商（OpenAI、Anthropic、Google、DeepSeek 等），通过智能路由算法从众多选择中为用户选出最适合当前任务的模型。
:::

::: tip 产品理念
以禅者之心，驭 AI 之力 —— 万千模型归一处，至简体验达至优。
:::

## 特色功能

### 大模型聚合平台

ZenMux 聚合了全球领先的闭源和开源大语言模型，在一个统一的平台上为开发者提供便捷的模型调用服务。

::: tip 一站式接入体验
只需创建一个 API Key，使用一套统一的 API 标准，即可完成对不同供应商、不同模型的调用。无需在多个平台注册账号、管理多个密钥、充值多个钱包。
:::

**主要优势：**

- **统一身份管理**：一个 API Key 管理所有供应商的访问权限
- **统一计费体系**：透明的用量统计和成本控制，集中式账户管理
- **丰富的模型选择**：涵盖 OpenAI、Anthropic、Google、DeepSeek 等多家主流供应商的最新模型

### 双协议支持

ZenMux 提供业界独特的双协议支持能力，让开发者能够以最熟悉的方式集成 AI 模型。

::: tip 灵活的协议选择
- **OpenAI 兼容协议**：通过 OpenAI 标准 API 统一调用平台的所有大模型
- **Anthropic 兼容协议**：通过 Anthropic 标准 API 统一调用平台的所有大模型，无缝集成到 Claude Code 等工具
:::

这意味着您可以根据项目需求和团队习惯，自由选择最适合的 API 协议，而无需担心模型供应商的差异。

### 高容量与高可用性

我们为每个大语言模型都储备了充足的调用容量，确保您的业务不受模型容量限制的影响。

::: tip 企业级服务保障
- **高容量储备**：几乎所有模型均达到 Tier 5 级别的容量配额
- **多供应商支持**：针对重要模型，我们引入了多家供应商的支持
- **自动故障转移**：当某家供应商容量饱和时，系统会自动切换到其他供应商，确保服务不中断
:::

通过多层次的容量储备和智能故障转移机制，ZenMux 为您的 AI 应用提供高可用性保障。

### 全平台模型"降智检测"

ZenMux 是业界首个对所有模型渠道进行公开、持续质量检测的平台。

::: tip 透明的质量保障
我们针对平台所有渠道的所有模型，定期进行 **Human Last Exam (HLE)** 测试，且测试过程和结果均在 GitHub 上开源公开。
:::

**核心机制：**

- **定期质量检测**：持续监控所有模型渠道的真实性和可靠性
- **开源透明**：完整的测试流程和结果在 GitHub 公开，接受社区监督
- **实时榜单**：测试结果实时公开到官网，形成动态的 HLE 榜单
- **质量追溯**：确保平台上的所有渠道、所有模型均真实可靠，杜绝"降智"模型

通过这一机制，我们为开发者提供了可信赖的模型质量保障，让您在选择模型时更加放心。

### AI 模型保险服务

ZenMux 是全球首个提供 **AI 模型保险服务**的平台，为模型调用效果提供兜底保障。

::: tip 创新的保险机制
我们为 AI 大模型使用过程中的效果不佳、幻觉、延迟过高等情况进行承保，通过每日自动检测和赔付服务，为您的 AI 应用质量托底。
:::

**保险服务特点：**

- **全面的保障范围**：覆盖模型效果不佳、幻觉输出、响应延迟过高等多种场景
- **自动检测与赔付**：每天对平台调用数据进行保险检测，赔付金额隔天自动到账
- **数据飞轮价值**：保险算法挖掘出的数据都是高质量的 bad case，可直接用于优化您的 AI 产品
- **持续改进支持**：通过保险赔付数据建立产品数据飞轮，不断完善 AI 应用效果

这一创新服务不仅为您的成本提供保障，更帮助您积累宝贵的优化数据。

### 智能模型路由

如果您希望在模型效果和使用成本之间找到最优平衡，ZenMux 的智能路由功能将是您的理想选择。

::: tip 自动化的最优选择
系统会根据请求内容和任务特征，自动选择最适合的模型进行响应，在保证效果的同时尽可能降低成本。
:::

**智能路由优势：**

- **效果与成本平衡**：自动在高性能模型和经济型模型之间做出最优选择
- **任务特征识别**：深度分析请求内容，匹配最适合的模型能力
- **持续学习优化**：基于历史数据不断优化路由策略
- **透明可控**：提供详细的路由决策日志，支持自定义路由规则

通过智能路由，您无需手动选择模型，即可获得"便宜且效果好"的最佳体验。

### 开发者友好的可观测性

ZenMux 以服务开发者为核心理念，提供全面的可观测性和调试能力。

::: tip 全方位的数据洞察
从多个维度深入了解 AI 模型的使用情况，帮助您快速定位问题、优化成本、提升效果。
:::

**核心功能：**

- **详细的日志分析**：完整记录每次 API 调用的请求和响应详情
- **成本花销聚合**：从项目、模型、时间等多个维度分析成本分布
- **用量统计分析**：实时监控 token 用量和调用频次
- **性能监控分析**：追踪响应时间、并发数等关键性能指标
- **模型效果对比**：支持不同模型的输出效果对比分析
- **可视化仪表板**：直观的图表和报表，快速掌握全局状况

完善的可观测性体系让您能够全面掌控 AI 应用的运行状态，及时发现并解决问题。

### 全球边缘节点

ZenMux 依托 Cloudflare 的强大基础设施，在全球部署了分布式边缘计算节点。

::: tip 全球加速网络
无论您的用户身在何处，都能从最近的边缘节点调用大模型，享受低延迟、高性能的服务体验。
:::

**技术优势：**

- **全球覆盖**：分布在全球各大洲的边缘计算节点
- **智能路由**：自动将请求路由到距离用户最近的节点
- **低延迟保障**：显著降低网络传输延迟，提升响应速度
- **高可用架构**：多节点冗余设计，确保服务稳定性

通过全球边缘节点部署，ZenMux 为您的全球化 AI 应用提供坚实的基础设施支持。

## 联系我们

如果您在使用过程中遇到任何问题，或有任何建议和反馈，欢迎通过以下方式联系我们：

- **官方网站**：<https://zenmux.ai>
- **技术支持邮箱**：[support@zenmux.ai](mailto:support@zenmux.ai)
- **商务合作邮箱**：[bd@zenmux.ai](mailto:bd@zenmux.ai)
- **Twitter**：[@ZenMuxAI](https://twitter.com/ZenMuxAI)
- **Discord 社区**：<http://discord.gg/vHZZzj84Bm>

更多联系方式和详细信息，请访问我们的[联系我们页面](/zh/help/contact)。
